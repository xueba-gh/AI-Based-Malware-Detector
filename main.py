import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from scapy.all import rdpcap, IP, TCP, UDP
import os
from collections import defaultdict
import pickle

# Function to load or initialize prediction statistics
def load_or_init_stats():
    if os.path.exists('prediction_stats.pkl'):
        with open('prediction_stats.pkl', 'rb') as f:
            return pickle.load(f)
    return {'total': 0, 'malicious': 0, 'benign': 0}

# Function to save prediction statistics
def save_stats(stats):
    with open('prediction_stats.pkl', 'wb') as f:
        pickle.dump(stats, f)

def analyze_pcap(file):
    packets = rdpcap(file)
    flows = defaultdict(lambda: {'fwd_packets': [], 'bwd_packets': []})

    for packet in packets:
        if IP in packet:
            ip_layer = packet[IP]
            src_ip = ip_layer.src
            dst_ip = ip_layer.dst
            protocol = ip_layer.proto
            timestamp = float(packet.time)

            if TCP in packet:
                transport_layer = packet[TCP]
                src_port = transport_layer.sport
                dst_port = transport_layer.dport
                flags = int(transport_layer.flags)  # Convert FlagValue to int
            elif UDP in packet:
                transport_layer = packet[UDP]
                src_port = transport_layer.sport
                dst_port = transport_layer.dport
                flags = 0
            else:
                continue

            flow_id = f"{src_ip}:{src_port}-{dst_ip}:{dst_port}-{protocol}"
            reverse_flow_id = f"{dst_ip}:{dst_port}-{src_ip}:{src_port}-{protocol}"

            packet_info = {
                'timestamp': timestamp,
                'length': len(packet),
                'flags': flags
            }

            if flow_id in flows:
                flows[flow_id]['fwd_packets'].append(packet_info)
            elif reverse_flow_id in flows:
                flows[reverse_flow_id]['bwd_packets'].append(packet_info)
            else:
                flows[flow_id]['fwd_packets'].append(packet_info)

    features = []
    for flow_id, flow_data in flows.items():
        fwd_packets = flow_data['fwd_packets']
        bwd_packets = flow_data['bwd_packets']
        all_packets = fwd_packets + bwd_packets

        if not all_packets:
            continue

        flow_duration = max(p['timestamp'] for p in all_packets) - min(p['timestamp'] for p in all_packets)
        
        feature = {
            'Flow Duration': flow_duration,
            'Total Fwd Packets': len(fwd_packets),
            'Total Backward Packets': len(bwd_packets),
            'Total Length of Fwd Packets': sum(p['length'] for p in fwd_packets),
            'Total Length of Bwd Packets': sum(p['length'] for p in bwd_packets),
            'Fwd Packet Length Max': max(p['length'] for p in fwd_packets) if fwd_packets else 0,
            'Fwd Packet Length Min': min(p['length'] for p in fwd_packets) if fwd_packets else 0,
            'Fwd Packet Length Mean': np.mean([p['length'] for p in fwd_packets]) if fwd_packets else 0,
            'Bwd Packet Length Max': max(p['length'] for p in bwd_packets) if bwd_packets else 0,
            'Bwd Packet Length Min': min(p['length'] for p in bwd_packets) if bwd_packets else 0,
            'Bwd Packet Length Mean': np.mean([p['length'] for p in bwd_packets]) if bwd_packets else 0,
            'Flow Bytes/s': sum(p['length'] for p in all_packets) / flow_duration if flow_duration > 0 else 0,
            'Flow Packets/s': len(all_packets) / flow_duration if flow_duration > 0 else 0,
            'Flow IAT Mean': np.mean(np.diff([p['timestamp'] for p in sorted(all_packets, key=lambda x: x['timestamp'])])) if len(all_packets) > 1 else 0,
            'Fwd IAT Total': sum(np.diff([p['timestamp'] for p in sorted(fwd_packets, key=lambda x: x['timestamp'])])) if len(fwd_packets) > 1 else 0,
            'Bwd IAT Total': sum(np.diff([p['timestamp'] for p in sorted(bwd_packets, key=lambda x: x['timestamp'])])) if len(bwd_packets) > 1 else 0,
            'Fwd PSH Flags': sum(p['flags'] & 0x08 for p in fwd_packets),
            'Bwd PSH Flags': sum(p['flags'] & 0x08 for p in bwd_packets),
            'Fwd URG Flags': sum(p['flags'] & 0x20 for p in fwd_packets),
            'Bwd URG Flags': sum(p['flags'] & 0x20 for p in bwd_packets),
            'FIN Flag Count': sum(p['flags'] & 0x01 for p in all_packets),
            'SYN Flag Count': sum(p['flags'] & 0x02 for p in all_packets),
            'RST Flag Count': sum(p['flags'] & 0x04 for p in all_packets),
            'PSH Flag Count': sum(p['flags'] & 0x08 for p in all_packets),
            'ACK Flag Count': sum(p['flags'] & 0x10 for p in all_packets),
            'URG Flag Count': sum(p['flags'] & 0x20 for p in all_packets),
        }
        features.append(feature)

    return pd.DataFrame(features)

def train_model(features):
    
    # In a real scenario, you'd need labeled data for training
    labels = np.random.choice([0, 1], size=len(features))
    
    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)
    
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    return model, X_test, y_test

def predict_malware(features, model):
    X = features.fillna(0)  # Replace NaN values with 0
    prediction = model.predict(X)
    confidence = model.predict_proba(X).max(axis=1)
    return prediction, confidence

def display_feature_importance(model, feature_names):
    importance = model.feature_importances_
    sorted_idx = np.argsort(importance)
    pos = np.arange(sorted_idx.shape[0]) + .5

    fig, ax = plt.subplots(figsize=(10, 12))
    ax.barh(pos[-20:], importance[sorted_idx][-20:], align='center')
    ax.set_yticks(pos[-20:])
    ax.set_yticklabels(np.array(feature_names)[sorted_idx][-20:])
    ax.set_xlabel('Feature Importance')
    ax.set_title('Top 20 Most Important Features')
    plt.tight_layout()
    st.pyplot(fig)

def main():
    st.set_page_config(page_title="AI-Based Network Malware Analyzer", page_icon="üîç", layout="wide")
    st.title("AI-Based Network Malware Analyzer")

    # Load prediction statistics
    stats = load_or_init_stats()

    # Sidebar
    st.sidebar.title("Statistics")
    st.sidebar.subheader("Prediction Statistics")
    st.sidebar.write(f"Total Predictions: {stats['total']}")
    st.sidebar.write(f"Malicious: {stats['malicious']}")
    st.sidebar.write(f"Benign: {stats['benign']}")

    # Create a pie chart for the sidebar (comment out)
    if stats['total'] > 0:
        fig, ax = plt.subplots()
        ax.pie([stats['malicious'], stats['benign']], labels=['Malicious', 'Benign'], autopct='%1.1f%%')
        ax.set_title('Overall Prediction Distribution')
        st.sidebar.pyplot(fig)

    uploaded_file = st.file_uploader("Choose a PCAP file", type=["pcap", "pcapng"])
    if uploaded_file is not None:
        st.write(f"File uploaded: {uploaded_file.name}")
        
        if st.button("Analyze and Predict"):
            try:
                with st.spinner("Analyzing PCAP file..."):
                    features = analyze_pcap(uploaded_file)

                if features.empty:
                    st.warning("No valid flows found in the PCAP file. Please try a different file.")
                    return
                
                st.subheader("File Information")
                st.write(f"Number of flows: {len(features)}")

                with st.spinner("Training model and making predictions..."):
                    model, X_test, y_test = train_model(features)
                    predictions, confidences = predict_malware(features, model)

                st.subheader("Analysis Results")
                malicious_count = sum(predictions)
                benign_count = len(predictions) - malicious_count

                # Update statistics
                stats['total'] += len(predictions)
                stats['malicious'] += malicious_count
                stats['benign'] += benign_count
                save_stats(stats)

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Malicious Flows", malicious_count)
                with col2:
                    st.metric("Benign Flows", benign_count)

                fig, ax = plt.subplots()
                ax.pie([malicious_count, benign_count], labels=['Malicious', 'Benign'], autopct='%1.1f%%')
                ax.set_title('Flow Distribution')
                st.pyplot(fig)

                st.subheader("Confidence Distribution")
                fig, ax = plt.subplots()
                sns.histplot(confidences, kde=True, ax=ax)
                ax.set_xlabel('Confidence')
                ax.set_title('Distribution of Prediction Confidences')
                st.pyplot(fig)

                if malicious_count > 0:
                    st.error(f"‚ö†Ô∏è Potential malware detected! {malicious_count} out of {len(predictions)} flows are classified as malicious.")
                else:
                    st.success("‚úÖ No malware detected. All flows are classified as benign.")

                st.subheader("What do these results mean?")
                st.write("""
                - **Malicious Flows**: These are network connections that exhibit characteristics commonly associated with malware or other malicious activities.
                - **Benign Flows**: These are normal, non-threatening network connections.
                - **Confidence**: This represents how sure the model is about its prediction for each flow.
                """)

                st.subheader("Feature Importance")
                display_feature_importance(model, features.columns)

                st.subheader("Model Performance")
                st.write("Note: These metrics are based on randomly generated labels for demonstration purposes.")
                st.write(classification_report(y_test, model.predict(X_test)))

                st.subheader("Next Steps")
                st.write("""
                1. If malicious flows were detected, investigate the specific IP addresses and ports involved.
                2. Check the affected devices for signs of compromise.
                3. Update your antivirus software and run a full system scan.
                4. Consider implementing additional network security measures.
                """)

            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
    else:
        st.info("Please upload a PCAP file to begin analysis.")

if __name__ == "__main__":
    main()
